{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab8_task (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **COMP 2211 Exploring Artificial Intelligence**\n",
        "## Convolutional Neural Network\n",
        "\n",
        "![fruit.jpg](https://cdn-images-1.medium.com/fit/t/1600/480/1*WaVMfzHIKyEvfRwvz84eGA.jpeg)"
      ],
      "metadata": {
        "id": "RMjuKcSy8nem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lab Tasks Procedure**\n",
        "1. Data preprocessing **(Task1)**\n",
        "2. Build the model **(Task2)**\n",
        "3. Compile the model\n",
        "4. Train the model\n",
        "5. Save the model"
      ],
      "metadata": {
        "id": "hRxYd14OLSYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check your Colab open the GPU accelerator:**\n",
        "\n",
        "1. 'Edit' -> 'Notebook settings':\n",
        "\n",
        "![gpu1.png](https://drive.google.com/uc?export=view&id=19RK_MicAY8J4BIY5g0i7bw6sr3WEFaDz)\n",
        "\n",
        "\n",
        "2. Set 'Hardware accelerator':\n",
        "\n",
        "![gpu2.png](https://drive.google.com/uc?export=view&id=1kTK1oZ-UWdIr0hxbXVT8GQDHMGHXVbLI)"
      ],
      "metadata": {
        "id": "cwtkXcztiXLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check your Colab device\n",
        "import tensorflow as tf  # Import tensorflow library\n",
        "import pprint            # Import pprint library for better print format\n",
        "device_name = tf.config.list_physical_devices()  # A list of divece name, which could contain CPU and GPU\n",
        "pprint.pprint(device_name)                       # Print the device_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_cgq_juiZMf",
        "outputId": "c3675c58-c115-4f19-d09b-69d34b284bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
            " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ZINC Submission**\n",
        "- **Task1**: Copy the ``data_preprocessing`` function to the given ``preprocessing.py`` file.\n",
        "- **Taks2**: Save your trained model as ``model_lab8.h5``.\n",
        "\n",
        "Zip these two files: ``preprocessing.py`` and ``model_lab8.h5``, to a single file named ``lab8_tasks.zip`` and **submit the ``.zip`` file.**"
      ],
      "metadata": {
        "id": "yPuANz8__RNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset"
      ],
      "metadata": {
        "id": "4FKDb00oMf9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Download neccesary files for sanity check\n",
        "\"\"\"\n",
        "username = input(\"Please enter your username: \")\n",
        "import getpass\n",
        "password = getpass.getpass(\"Please enter your password: \")\n",
        "url = f'https://{username}:{password}@course.cse.ust.hk/comp2211/labs/lab8/task_data.zip'\n",
        "!wget $url -O task_data.zip\n",
        "!unzip -q task_data.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIjZVtTth4ZK",
        "outputId": "81fe816d-181e-4795-90b9-3d5df8baf837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your username: zraoac\n",
            "Please enter your password: ··········\n",
            "--2022-04-17 23:19:23--  https://zraoac:*password*@course.cse.ust.hk/comp2211/labs/lab8/task_data.zip\n",
            "Resolving course.cse.ust.hk (course.cse.ust.hk)... 143.89.41.176\n",
            "Connecting to course.cse.ust.hk (course.cse.ust.hk)|143.89.41.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 401 Unauthorized\n",
            "Authentication selected: Basic realm=\"Enter Your CSD PC/Unix Password\"\n",
            "Reusing existing connection to course.cse.ust.hk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71825930 (68M) [application/zip]\n",
            "Saving to: ‘task_data.zip’\n",
            "\n",
            "task_data.zip       100%[===================>]  68.50M  15.7MB/s    in 5.6s    \n",
            "\n",
            "2022-04-17 23:19:30 (12.2 MB/s) - ‘task_data.zip’ saved [71825930/71825930]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: **Fruit Recognition**\n",
        "---\n",
        "- Training set size: 15178.\n",
        "- Number of classes: 33.\n",
        "- Image size: 100 x 100 pixels."
      ],
      "metadata": {
        "id": "QgwgslIrJ4aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Import os library\n",
        "\n",
        "data_dir = './task_data'\n",
        "# os.list() returns the list of subfolder's name\n",
        "# sorted() rearranges the order of the list\n",
        "category_list = sorted(os.listdir(data_dir)) \n",
        "\n",
        "# Create a dict mapping the category name to the class index\n",
        "# The number of label should be 33 (0 to 32)\n",
        "cate2Idx = {}\n",
        "for i in range(len(category_list)):\n",
        "  cate2Idx[category_list[i]] = i\n",
        "print(cate2Idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bANmS4K6_XOs",
        "outputId": "a8ceb9a5-3d51-4a8b-d961-819e7562645b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Apple Braeburn': 0, 'Apple Granny Smith': 1, 'Apricot': 2, 'Avocado': 3, 'Banana': 4, 'Blueberry': 5, 'Cactus fruit': 6, 'Cantaloupe': 7, 'Cherry': 8, 'Clementine': 9, 'Corn': 10, 'Cucumber Ripe': 11, 'Grape Blue': 12, 'Kiwi': 13, 'Lemon': 14, 'Limes': 15, 'Mango': 16, 'Onion White': 17, 'Orange': 18, 'Papaya': 19, 'Passion Fruit': 20, 'Peach': 21, 'Pear': 22, 'Pepper Green': 23, 'Pepper Red': 24, 'Pineapple': 25, 'Plum': 26, 'Pomegranate': 27, 'Potato Red': 28, 'Raspberry': 29, 'Strawberry': 30, 'Tomato': 31, 'Watermelon': 32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten"
      ],
      "metadata": {
        "id": "JbdArU_kk-h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data preprocessing\n",
        "\n",
        "We need to load the data and store them in the appropriate format."
      ],
      "metadata": {
        "id": "bpzp1gc6x0Zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1\n",
        "\n",
        "Complete the following code.\n",
        "\n",
        "1. Load images.\n",
        "2. Resize images from 100 x 100 to 28 x 28.\n",
        "3. Save the image data in **x**.\n",
        "4. Save the corresponding class index in **y**.\n",
        "\n",
        "**Here are some useful functions that might be useful for you:**\n",
        "\n",
        "- cv2.imread(filepath): \n",
        "  - ***Input*** filepath -- A string of image path.\n",
        "  - ***Return*** -- A numpy array.\n",
        "  ```python\n",
        "  img = cv2.imread(\"example.png\"). # Load the data of example.png\n",
        "  ```\n",
        "- cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB): Convert the color space from BGR to RGB\n",
        "  - ***Input*** img_data -- A numpy array of image data.\n",
        "  - ***Return*** -- A numpy array.\n",
        "  ```python\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB). # Convert the color space of image from BGR To RGB\n",
        "  ```\n",
        "- cv2.resize(img_data, size):\n",
        "  - ***Input*** img_data -- A numpy array of image data.\n",
        "  - ***Input*** size -- A tuple of integers.\n",
        "  - ***Return*** - A numpy array.\n",
        "  ```python\n",
        "  img = cv2.resize(img, (100, 80)). # Resize the image to 100 x 80\n",
        "  ```"
      ],
      "metadata": {
        "id": "sphRon-6zBR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: data_dir(str)  -- the path of data.\n",
        "#        cate2Idx(dict) -- mapping the category name to class index.\n",
        "# Return: x(array) -- the images data, the shape in this task should be (15178, 28, 28, 3).\n",
        "#         y(array) -- the label of images, the shape in this task should be (15178,).\n",
        "# Here are some useful functions that might be useful for you:\n",
        "#     cv2.imread()   -- read image data.\n",
        "#     cv2.cvtColor() -- convert the color space.\n",
        "def data_preprocessing(data_dir, cate2Idx):\n",
        "  x = None\n",
        "  y = None\n",
        "  #### TODO HERE\n",
        "\n",
        "\n",
        "\n",
        "  #### END TODO\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "HOvbn-BGkzKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = data_preprocessing(data_dir, cate2Idx)\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNdgiyFhRNtf",
        "outputId": "e8190324-b23a-4901-e9b2-613df2f58f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15178, 28, 28, 3) (15178,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset to train and test parts based on the ratio of 0.2\n",
        "# x_train is a NumPy array of RGB image data with shape (12142, 28, 28, 3)\n",
        "# y_train is a NumPy array of digit labels (in range 0-32) with shape (12142,)\n",
        "# x_test is a NumPy array of RGB image data with shape (3036, 28, 28, 3)\n",
        "# y_test is a NumPy array of digit labels (in range 0-32) with shape (3036,)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# There are 33 classes and classes are represented as unique integers(0 to 32).\n",
        "# Transform the integer into a 33 element binary vector.\n",
        "y_train = np_utils.to_categorical(y_train, len(category_list))\n",
        "y_test = np_utils.to_categorical(y_test, len(category_list))"
      ],
      "metadata": {
        "id": "CXS-wvfjRm7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build the model\n",
        "\n",
        "### Task 2\n",
        "\n",
        "Complete the following code. You need to built your own model with at least 3 convolutional layers and 2 dense layers. "
      ],
      "metadata": {
        "id": "pUmXtdNd1ONd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - Only use Conv2D, MaxPooling2D, Dense, Dropout and Flatten.\n",
        "# - At least 3 convolutional layers and 2 dense layers.\n",
        "def custom_model():\n",
        "  model = None\n",
        "  #### TODO HERE\n",
        "\n",
        "\n",
        "\n",
        "  #### END TODO\n",
        "  return model"
      ],
      "metadata": {
        "id": "azRtraFsmqTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = custom_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ddGuQXP2pQF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Compile the Model"
      ],
      "metadata": {
        "id": "YqnopwQx4r_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "# Use crossentropy loss function since there are two or more label classes\n",
        "# Use adam algorithm (a stochastic gradient descent method)\n",
        "# Use accuracy as metric\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Tn-OD4UPpafR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train the model\n",
        "\n",
        "You can also try different parameters."
      ],
      "metadata": {
        "id": "KAoxaqjd4ytm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model, i.e., train the model\n",
        "# Specify training data and labels\n",
        "# Specify batch size, i.e., number of samples per gradient update\n",
        "# Specify validation data, i.e., data on which to evaluate the loss\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "GuvzVJ3PrEVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Save the model\n",
        "\n",
        "Save your model and submit it to ZINC"
      ],
      "metadata": {
        "id": "eBU_Mk1R4-yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the mdoel to an HDFS file\n",
        "model_name = 'model_lab8.h5'              # Define model name\n",
        "model.save(model_name, save_format='h5')  # Save the model"
      ],
      "metadata": {
        "id": "7fNc59JO5LTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}