{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "Note: \n",
    "1. It is ok to define more helper functions, but not necessary for finishing the homework.\n",
    "2. The imported libraries are sufficient to complete the TODO intructions. Please consult TA Vincent Cheng for permission to use additional libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding of MLP\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "        return x\n",
    "\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (c)\n",
    "Note: run this code after code for (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "#######################\n",
    "# TODO: define train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = \n",
    "test_loader = \n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "# Build MLP\n",
    "mlp = MLP()\n",
    "print(f'The MLP structure you built is as follow: \\n{mlp}')\n",
    "\n",
    "# Train MLP\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the MLP for 3 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "# Evaluate MLP\n",
    "mlp.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(mlp, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(mlp, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #######################\n",
    "        # TODO: initialize neural network components\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #######################\n",
    "        # TODO: define forwarding for CNN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #######################\n",
    "\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for (f)\n",
    "Note: run this code after code for (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Prepare dataset\n",
    "train_set = torchvision.datasets.MNIST(\"data/\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_set = torchvision.datasets.MNIST(\"data/\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "#######################\n",
    "# TODO: define the train_loader, test_loader using train_set, test_set, the utils.data.DataLoader function\n",
    "train_loader = \n",
    "test_loader = \n",
    "#######################\n",
    "\n",
    "\n",
    "# Build Convolutional Neural Network (CNN)\n",
    "cnn = CNN()\n",
    "print(f'The CNN structure you built is as follow: \\n{cnn}')\n",
    "\n",
    "# Train CNN\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "#######################\n",
    "# TODO: Train the CNN for 3 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "# Evaluate CNN\n",
    "cnn.eval() # toggle evaluation mode\n",
    "# define an evaluation function\n",
    "def evaluate_a_model(model, dataloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            output = model(inputs)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "    accuracy = 100.*correct / len(dataloader.dataset)\n",
    "    return accuracy\n",
    "# evaluate on training data\n",
    "train_acc = evaluate_a_model(cnn, train_loader)\n",
    "# evaluate on training data\n",
    "test_acc = evaluate_a_model(cnn, test_loader)\n",
    "print(f'\\nFinal training accuracy: {train_acc:.2f}%\\nFinal testing accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ae69442b1fc44f14b5ed9e4e267de3f8165086ea0eeb0bf8dc28231d964179e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
